try:
  # %tensorflow_version only exists in Colab.
  %tensorflow_version 2.x
except Exception:
  pass

from __future__ import absolute_import, division, print_function, unicode_literals
#------------------------------------------------------------------------------------------
# TensorFlow and tf.keras
import tensorflow as tf
from tensorflow import keras
from keras.utils import np_utils

# Helper libraries
import numpy as np
import matplotlib.pyplot as plt

print(tf.__version__)

#-----------------------------------------------------------------------------------------------
#Import the Image dataset
tf.random.set_seed(100)
mnist = keras.datasets.mnist

(train_images, train_labels), (test_images, test_labels) = mnist.load_data()
#Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz
#11493376/11490434 [==============================] - 0s 0us/step
#----------------------------------------------------------------------------------------------------

num_train, img_rows, img_cols =  train_images.shape
num_test, img_rows, img_cols =  test_images.shape
num_classes = len(np.unique(train_labels))
#------------------------------------------------------------------------------------------------------
#plot the image
plt.figure()
plt.imshow(train_images[0])
plt.colorbar()
plt.grid(False)
plt.show()
#-----------------------------------------------------------------------------------------------------
#preprocessing the dataset
train_images = train_images / 255.0
test_images = test_images / 255.0

class_names = ['0','1','2','3','4','5','6','7','8','9']
plt.figure(figsize=(15,15))
for i in range(25):
  plt.subplot(5,5,i+1)
  plt.xticks([])
  plt.yticks([])
  plt.grid(False)
  plt.imshow(train_images[i],cmap = plt.cm.binary)
  plt.xlabel(class_names[train_labels[i]])
plt.show()
#-----------------------------------------------------------------------------------------------------
#Model building
#we are going to build neural network model
#Architecture  of NN: Layers,  units per layer
#Model will contain following layers:

#Flatten(Input) -> Dense(100, activation='relu') -> Dense(10, activation='softmax')
#it takes 28X28 values of pixels and convert it to list of 784(conversion from matrix to list)
#this list will become ip for first hidden layer, we will use hidden layer of 128 units ,
#then we have op layer having 10 unit. each unit represents a class.

#Use 'Adam' optimizer

#Use 'accuracy' as your metric

model = keras.Sequential([
                          keras.layers.Flatten(input_shape = (28, 28)),
                          keras.layers.Dense(128, activation = 'relu'),
                          keras.layers.Dense(10, activation = 'softmax')
])

model.compile(optimizer= 'adam',
              loss = 'parse_categorical_crossentropy',
              metrics =['accuracy'])
              
#-----------------------------------------------------------------------------------------------------
#training of model
history = model.fit(train_images, train_labels, batch_size=512, validation_data = (test_images, test_labels), epochs=10)
#i have achieved accuracy of 97% validated with test data

#--------------------------------------------------------------------------------------------------------
#testing for overfitting and underfitting
# summarize history for accuracy
def plot_acc(history):
  plt.plot(history.history['accuracy'])
  plt.plot(history.history['val_accuracy'])
  plt.title('model accuracy')
  plt.ylabel('accuracy')
  plt.xlabel('epoch')
  plt.legend(['train', 'test'], loc='upper left')
  plt.show()
# summarize history for loss
def plot_loss(history):
  plt.plot(history.history['loss'])
  plt.plot(history.history['val_loss'])
  plt.title('model loss')
  plt.ylabel('loss')
  plt.xlabel('epoch')
  plt.legend(['train', 'test'], loc='upper left')
  plt.show()
  
plot_acc(history)
plot_loss(history)



